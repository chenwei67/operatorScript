# collect.sh 指标采集清单（CK -> SR 迁移）

此脚本目的是提前获取迁移过程前的预检和过程中的反压数据来源

默认输出目录：

- `OUTPUT_DIR` 未指定时为 `$(pwd)/output`（见脚本参数处理逻辑）
- 目录结构：`$OUTPUT_DIR/`、`$OUTPUT_DIR/timeseries/`、`$OUTPUT_DIR/snapshots/`

压力风险说明（粗略）：

- 高：可能对线上 ClickHouse（尤其是 `system.query_log`/业务大表）造成明显 CPU/IO/内存压力
- 中：对 ClickHouse 有可见压力，但通常可通过缩短窗口/限制线程缓解
- 低：通常影响有限（但在超大集群/极端基数下仍可能变慢）

## 一、汇总入口与归档

| 采集内容/指标      | 统计方式或公式（脚本口径）                                                                 | 导出位置（相对 `$OUTPUT_DIR` 或 JSON 字段） | 压力风险 | 数据读取类型      | 在 CK -> SR 迁移中的作用             |
| ------------ | ----------------------------------------------------------------------------- | -------------------------------- | ---- | ----------- | ----------------------------- |
| 汇总 JSON（总入口） | 汇总各类 CSV/Prom 路径与摘要信息（cluster_overview/tables/schemas/traffic/resources/meta） | `migration_metrics.json`         | 低    | 元信息（聚合索引）   | 统一入口，便于自动化解析与归档，作为迁移评估报告的数据索引 |
| 归档压缩包（可选）    | `tar -czf "${OUTPUT_DIR}.tar.gz"`，成功后删除原目录                                    | `${OUTPUT_DIR}.tar.gz`（与输出目录同级）  | 低    | 文件打包（不查 CK） | 便于跨环境传输、留档与离线分析               |

## 二、集群规模与硬件信息

对最终方案制定：用于 SR 侧容量规划（节点数、CPU/内存配比、存储盘型与容量预留）、分片/副本规划与迁移并发上限估算；同时以 CK 当前拓扑为“对照基线”，决定是否需要先扩容 SR 或调整分布策略。

迁移前预检：检查现网磁盘水位、节点规格是否有足够冗余承受“迁移+双写/同步”叠加负载

迁移中反压：把 CPU/内存/磁盘水位与负载作为限流信号，动态控制全量导入/增量同步的并发、批大小与速率，避免把压力传导到 CK 或 SR 造成雪崩。

| 采集内容/指标                    | 统计方式或公式（脚本口径）                                                                                                                                                                                                            | 导出位置（相对 `$OUTPUT_DIR` 或 JSON 字段）                                                                              | 压力风险            | 数据读取类型       |
| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------- | --------------- | ------------ |
| 集群节点数                      | `kubectl get nodes --no-headers \| wc -l`                                                                                                                                                                                | `migration_metrics.json.cluster_overview.cluster_node_count`                                                  | 低               | 元信息（K8s API） |
| CHI 分片/副本与期望节点数            | 从 `kubectl get chi ... jsonpath` 取 `shardsCount/replicasCount`，并计算 `shards*replicas`                                                                                                                                     | `migration_metrics.json.cluster_overview.chi_shards_count` / `chi_replicas_count` / `chi_expected_node_count` | 低               | 元信息（CRD 配置）  |
| K8s 节点硬件清单（核数/内存）          | `kubectl get nodes -o jsonpath ...` 导出 `cpu_capacity/memory_capacity` 及 allocatable                                                                                                                                      | `snapshots/cluster_k8s_nodes.csv`                                                                             | 低               | 元信息（多节点清单）   |
| K8s 节点磁盘容量与使用量（来自 VM）      | VictoriaMetrics `api/v1/query` 拉 `node_filesystem_size_bytes/free_bytes`，按 node+mountpoint 计算 `used_bytes/used_percent`（过滤 tmpfs/overlay 等）                                                                              | `snapshots/cluster_node_disk_usage.csv`                                                                       | 低（对 CK）/中（对 VM） | 时序聚合（多点度量）   |
| 执行节点硬件快照（CPU 核数/内存/磁盘/负载等） | 从 `/proc/meminfo`、`/proc/loadavg`、`/proc/cpuinfo`、`df`、`/proc/sys/fs/file-nr`、`/proc/net/sockstat` 采集：`cpu_cores/memory_total_bytes/memory_used_bytes/disk_total_bytes/disk_used_bytes/load_avg/cpu_flags/swap/fd/tcp` 等 | `migration_metrics.json.resources.node_level.*`                                                               | 低               | 本机元信息（单节点快照） |

## 三、部署与配置（可复现性/对齐）

对最终方案制定：把 CK 现网的部署参数与关键配置“固化”为可对照的基线，用于决定 SR 侧部署形态（K8s/资源配额/存储类/副本）、以及迁移期间是否需要对 CK/SR 做特定调参以支撑双写或同步。

| 采集内容/指标                | 统计方式或公式（脚本口径）                                                              | 导出位置（相对 `$OUTPUT_DIR` 或 JSON 字段）                     | 压力风险 | 数据读取类型       |
| ---------------------- | -------------------------------------------------------------------------- | ---------------------------------------------------- | ---- | ------------ |
| Helm release 用户 values | `helm list` 后对每个 release 执行 `helm get values`                              | `helm/<release>.yaml`                                | 低    | 元信息（Helm 配置） |
| ClickHouse 版本          | `SELECT version()`                                                         | `migration_metrics.json.cluster_overview.ck_version` | 低    | 元信息（单行查询）    |
| system.settings        | `SELECT name,value,changed,description FROM system.settings ORDER BY name` | `snapshots/system_settings.csv`                      | 低    | 元信息（系统表多行）   |
| system.build_options   | `SELECT name,value FROM system.build_options ORDER BY name`                | `snapshots/system_build_options.csv`                 | 低    | 元信息（系统表多行）   |

## 四、表结构与数据体量

对最终方案制定：用表级规模与 schema 兼容性决定迁移分批顺序（先小后大/先冷后热/先非关键后关键）、SR 分桶/分区策略与副本规划；同时为双写与 CK->SR 同步选择“哪些表先纳入、哪些表延后”提供量化依据。

| 采集内容/指标            | 统计方式或公式（脚本口径）                                                                                                                                               | 导出位置（相对 `$OUTPUT_DIR` 或 JSON 字段） | 压力风险 | 数据读取类型       |
| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------- | ---- | ------------ |
| 全量表统计（行数/压缩/解压大小）  | `clusterAllReplicas(system.tables)` 取表清单；LEFT JOIN `clusterAllReplicas(system.parts)`（限定 replica_num=1）聚合 `sum(rows/bytes_on_disk/data_uncompressed_bytes)` | `table_stats.csv`                | 中    | 系统表聚合（多表多行）  |
| 全量表 schema（列级）     | `system.columns` 导出 `database/table/column/type/default_*`                                                                                                  | `table_schema.csv`               | 低-中  | 系统表扫描（多表多列）  |
| business 表 TTL 元数据 | 从 `system.tables.engine_full` 提取 TTL 表达式与 TTL 数值                                                                                                            | `business_ttl.csv`               | 低    | 系统表解析（元信息多行） |

## 五、流量与查询画像

对最终方案制定：识别日业务低峰时段，决定同步数据时段和并发、批次；识别热点表，人查与机查模式，并决定T0查询时间范围评估。

迁移中反压：把失败率、拒绝/超时、p95/p99 延迟等作为“体验型”反压信号，配合写入量时序做分级限流；在双写或同步阶段，一旦指标恶化可按表/按用户组降低写入速率或暂停增量。

| 采集内容/指标                         | 统计方式或公式（脚本口径）                                                                                                                                                                            | 导出位置（相对 `$OUTPUT_DIR` 或 JSON 字段）                                                                                  | 压力风险            | 数据读取类型                |
| ------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- | --------------- | --------------------- |
| business 表写入行数分桶（逐表）            | 从 VM 拉取计数器 `default_key_process_count{processName="normal_ck",logType!="dynamic_graph_log"}`，按 `logType` 聚合 `increase(...[bucket])`；输出为 Prom 格式时序                                        | `timeseries/business_table_writes/business_table_writes_timeseries.prom`（目录为 `timeseries/business_table_writes/`） | 低（对 CK）/中（对 VM） | 时序聚合（VictoriaMetrics） |
| query_log Select 按表分桶（次数）       | 过滤 `query_kind=Select`，按表+时间桶聚合 `count()`                                                                                                                                                | `timeseries/query_log_reads/`（目录内拆分为多文件）                                                                          | 中-高             | 系统日志表扫描（大量行）          |
| query_log Select 按用户组分桶（次数）     | 在上述 Select 基础上，将 `user` 聚合到特定业务用户与非人类流量两类，按表+时间桶统计查询次数                                                                                                                                   | `timeseries/query_log_reads_by_user_group.csv`                                                                    | 中-高             | 系统日志表扫描（按用户聚合）        |
| query_log 失败/拒绝/超时分桶（结果面）       | `clusterAllReplicas(system.query_log)` 统计 `type in (QueryFinish, ExceptionBeforeStart, ExceptionWhileProcessing)`，按 `query_kind+时间桶` 聚合 `failures/denials/timeouts`（同时支持 root/非 root 分组） | `timeseries/query_log_failures_timeseries.csv` / `timeseries/query_log_failures_timeseries_by_user_group.csv`     | 高               | 系统日志表扫描（异常路径）         |
| query_log 延迟画像（p50/p95/p99/avg） | `clusterAllReplicas(system.query_log)` 按 `query_kind+时间桶` 聚合 `quantile/avg/sum(read_bytes)/max(memory_usage)`                                                                            | `timeseries/query_log_latency_timeseries.csv`                                                                     | 高               | 系统日志表扫描（大量行 + 聚合）     |
| query_log 延迟画像（root/非 root 聚合）  | 在上述延迟画像基础上，将 `user` 聚合为 `root` 与 `non_root` 两组（保留原不聚合版本）                                                                                                                                 | `timeseries/query_log_latency_timeseries_by_user_group.csv`                                                       | 高               | 系统日志表扫描（按用户聚合）        |
| Top 慢查询（按 normalized_query 聚合）  | `GROUP BY normalized_query` 聚合 `count/p95/avg/sum(read_bytes)/max(memory_usage)`，按 p95 降序取 TopN                                                                                          | `timeseries/slow_queries_top.csv`                                                                                 | 高               | 系统日志表扫描（TopN 聚合）      |
| Top 慢查询（root/非 root 聚合）         | 在 Top 慢查询基础上，将 `user` 聚合为 `root` 与 `non_root` 两组（保留原不聚合版本）                                                                                                                               | `timeseries/slow_queries_top_by_user_group.csv`                                                                   | 高               | 系统日志表扫描（TopN+按用户聚合）   |
| 查询时间范围分布（按表，启发式正则解析 SQL）        | 扫 `system.query_log`，对 `ql.query` 做多类正则解析估算范围天数，按表统计比例与分位；带 `SETTINGS max_threads/max_execution_time`                                                                                    | `timeseries/query_time_range_distribution.csv`                                                                    | 高               | 系统日志表扫描（正则解析 SQL，启发式） |
| 查询时间范围分布（root/非 root 聚合，启发式）    | 在启发式查询时间范围分布基础上，将 `user` 聚合为 `root` 与 `non_root` 两组（保留原不聚合版本）                                                                                                                            | `query_time_range_distribution_by_user_group.csv`                                                                 | 高               | 系统日志表扫描（正则+按用户聚合）     |
| 查询时间范围分布（按表，严格版）                | 仅基于配置时间列上的显式边界（时间戳/日期）估算范围天数，忽略与时间列无关的日期/INTERVAL，按表统计比例与分位                                                                                                                              | `timeseries/query_time_range_distribution_strict.csv`                                                             | 高               | 系统日志表扫描（严格解析，命中较少）    |
| 查询时间范围分布（root/非 root，严格版）       | 严格版查询时间范围分布基础上，将 `user` 聚合为 `root` 与 `non_root` 两组                                                                                                                                       | `query_time_range_distribution_strict_by_user_group.csv`                                                          | 高               | 系统日志表扫描（严格+按用户聚合）     |

## 六、资源监控（来自 VictoriaMetrics）

对最终方案制定：以 CK 现网的资源峰值与波动作为“迁移目标约束”，为 SR 侧的容量、资源配额与性能验收口径提供对照基线；同时用于定义迁移期间的监控看板与告警阈值。

迁移前预检：用迁移窗口期的资源基线判断是否具备上线条件（是否存在长期高负载、IO 抖动、磁盘 IO await 高、频繁 throttle 等），必要时先做扩容/均衡/调参再启动迁移。

迁移中反压：把节点与 Pod 资源时序、ClickHouseMetrics（PartsActive、MemoryTracking、连接数、活跃线程等）作为实时健康度信号，触发自动/人工限流（降低并发、缩小批次、暂停同步、延后对账校验）以保护线上。

| 采集内容/指标                              | 统计方式或公式（脚本口径）                                                                                                                                                                                                   | 导出位置（相对 `$OUTPUT_DIR` 或 JSON 字段）                      | 压力风险            | 数据读取类型                       |
| ------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------- | --------------- | ---------------------------- |
| CK Pod 资源时序（VM query_range）          | 多条 PromQL，按窗口计算 `avg_over_time/max_over_time`（CPU/内存/网络/磁盘 IO/Throttle）                                                                                                                                         | `timeseries/ck_pod_usage_timeseries.prom`             | 低（对 CK）/中（对 VM） | 时序聚合（VictoriaMetrics / Pod）  |
| 集群节点资源时序（VM query_range）             | 多条 PromQL，按窗口 `avg/max`（CPU/内存/磁盘/Swap/网络/IO/Load/磁盘 IO 延迟 await_ms）                                                                                                                                            | `timeseries/cluster_node_usage_timeseries.prom`       | 低（对 CK）/中（对 VM） | 时序聚合（VictoriaMetrics / Node） |
| 集群节点文件系统时序（VM query_range）           | 多条 PromQL，按窗口 `avg` 输出 `node_filesystem_size/free/used_bytes/used_percent`（过滤 tmpfs/overlay 等）                                                                                                                  | `timeseries/cluster_filesystem_usage_timeseries.prom` | 低（对 CK）/中（对 VM） | 时序聚合（磁盘用量，多节点多挂载）            |
| ClickHouseMetrics 时序（VM query_range） | 从 VM 拉取 `ClickHouseMetrics_{PartsActive,MemoryTracking,Merge,Query,GlobalThreadActive,TCPConnection,HTTPConnection,MySQLConnection,PostgreSQLConnection,InterserverConnection}`，按 `instance` 聚合后按窗口输出 `avg/max` | `timeseries/clickhouse_metrics_timeseries.prom`       | 低（对 CK）/中（对 VM） | 时序聚合（CK 内部指标，多实例）            |

## 七、其他

1. 考虑从events相关指标中获取查询失败和错误指标
2. events/xdr的ck-exporter中获取慢查询指标，更准确
3. 是否存在更新场景，是的话增加mutation相关指标
